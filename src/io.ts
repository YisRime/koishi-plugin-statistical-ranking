import { Context } from 'koishi'
import { StatRecord } from './index'
import { Utils } from './utils'
import * as fs from 'fs'
import * as path from 'path'

/**
 * ç»Ÿè®¡æ•°æ®å¯¼å…¥å¯¼å‡ºå·¥å…·é›†
 */
export const io = {
  /**
   * å¯¼å‡ºç»Ÿè®¡æ•°æ®åˆ°æ–‡ä»¶
   * @param {Context} ctx Koishi ä¸Šä¸‹æ–‡
   * @param {string} filename æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
   * @param {Object} options å¯¼å‡ºé€‰é¡¹
   * @param {string} [options.userId] ç­›é€‰ç‰¹å®šç”¨æˆ·ID
   * @param {string} [options.platform] ç­›é€‰ç‰¹å®šå¹³å°
   * @param {string} [options.guildId] ç­›é€‰ç‰¹å®šç¾¤ç»„ID
   * @param {string} [options.command] ç­›é€‰ç‰¹å®šå‘½ä»¤
   * @param {number} [options.batchSize] æ‰¹å¤„ç†å¤§å°ï¼Œé»˜è®¤ä¸º200æ¡/æ‰¹
   * @returns {Promise<{count: number, batches: number, files: Array<{count: number, path: string, filename: string, batch: number, totalBatches: number}>}>} å¯¼å‡ºç»“æœ
   * @throws {Error} å¯¼å‡ºå¤±è´¥æ—¶æŠ›å‡ºé”™è¯¯
   */
  async exportToFile(ctx: Context, filename: string, options: {
    userId?: string, platform?: string, guildId?: string, command?: string, batchSize?: number
  }) {
    const query = Object.fromEntries(
      Object.entries({...options, batchSize: undefined})
        .filter(([_, value]) => Boolean(value))
    );
    const records = await ctx.database.get('analytics.stat', query)
    if (!records.length) throw new Error('å†å²æ•°æ®ä¸ºç©º')
    const timestamp = new Date().toISOString().replace(/[:T.]/g, '-').substring(0, 19)
    const batchSize = options.batchSize || 200
    const totalRecords = records.length
    const batches = Math.ceil(totalRecords / batchSize)
    const exportFiles = []
    const statDir = Utils.getDataDirectory()
    for (let batch = 0; batch < batches; batch++) {
      const start = batch * batchSize
      const end = Math.min((batch + 1) * batchSize, totalRecords)
      const batchRecords = records.slice(start, end)
      const outputFilename = batches === 1
        ? `${filename}-${timestamp}.json`
        : `${filename}-${timestamp}-${batches}-${batch+1}.json`
      const filePath = path.join(statDir, outputFilename)
      fs.writeFileSync(
        filePath,
        JSON.stringify(batchRecords.map(({ id, ...rest }) => rest), null, 2),
        'utf-8'
      )
      exportFiles.push({
        count: batchRecords.length,
        path: filePath,
        filename: outputFilename,
        batch: batch + 1,
        totalBatches: batches
      })
    }
    return { count: totalRecords, batches, files: exportFiles }
  },

  /**
   * åˆ—å‡ºå¯å¯¼å…¥çš„ç»Ÿè®¡æ•°æ®æ–‡ä»¶
   * @param {Context} ctx Koishi ä¸Šä¸‹æ–‡
   * @returns {Promise<{files: string[], fileInfo: Record<string, any>}>} æ–‡ä»¶åˆ—è¡¨å’Œè¯¦ç»†ä¿¡æ¯
   */
  async listImportFiles(ctx: Context) {
    const statDir = Utils.getDataDirectory()
    const files = await fs.promises.readdir(statDir)
    const statFiles = files.filter(file =>
      file.endsWith('.json') && (file.includes('stat') || file.includes('analytics'))
    )
    if (!statFiles.length) return { files: [], fileInfo: {} }
    const fileInfo = {}
    const batchGroups = new Map()
    // å¤„ç†æ–‡ä»¶ä¿¡æ¯
    for (const file of statFiles) {
      const stats = await fs.promises.stat(path.join(statDir, file))
      const batchMatch = file.match(/(.*)-(\d+)-(\d+)\.json$/)
      const isBatch = !!batchMatch
      fileInfo[file] = {
        mtime: stats.mtime.toLocaleString(),
        timestamp: stats.mtime.getTime(),
        isBatch,
        batchInfo: isBatch ? {
          base: batchMatch[1],
          total: parseInt(batchMatch[2]),
          current: parseInt(batchMatch[3])
        } : undefined
      }
      // æ”¶é›†æ‰¹æ¬¡ç»„
      if (isBatch) {
        const [, base, total, ] = batchMatch
        const key = `${base}-total${total}`
        if (!batchGroups.has(key)) batchGroups.set(key, [])
        batchGroups.get(key).push(file)
      }
    }
    // å¤„ç†æ‰¹æ¬¡ç»„
    const batchGroupFiles = []
    for (const [, files] of batchGroups.entries()) {
      if (files.length <= 1) continue
      const firstFile = files[0]
      const groupInfo = firstFile.match(/(.*)-(\d+)-(\d+)\.json$/)
      if (!groupInfo) continue
      const [, base, total, ] = groupInfo
      const groupName = `${base}(N=${total})`
      fileInfo[groupName] = {
        mtime: new Date(Math.max(...files.map(f => fileInfo[f].timestamp))).toLocaleString(),
        timestamp: Math.max(...files.map(f => fileInfo[f].timestamp)),
        isBatch: true,
        isGroup: true,
        batchInfo: {
          base,
          total: parseInt(total),
          files: files.sort((a, b) => {
            const aMatch = a.match(/-(\d+)-(\d+)/)
            const bMatch = b.match(/-(\d+)-(\d+)/)
            if (aMatch && bMatch) {
              // å¦‚æœæ€»æ‰¹æ¬¡ç›¸åŒåˆ™æŒ‰å½“å‰æ‰¹æ¬¡æ’åº
              if (aMatch[1] === bMatch[1]) {
                return parseInt(aMatch[2]) - parseInt(bMatch[2]);
              }
            }
            return 0;
          })
        }
      }
      batchGroupFiles.push(groupName)
    }
    // æ’åºæ–‡ä»¶åˆ—è¡¨
    const sortedFiles = [...batchGroupFiles, ...statFiles].sort((a, b) => {
      const aInfo = fileInfo[a], bInfo = fileInfo[b]
      return aInfo.isGroup !== bInfo.isGroup
        ? (aInfo.isGroup ? -1 : 1)
        : (bInfo.timestamp - aInfo.timestamp)
    })
    return { files: sortedFiles, fileInfo }
  },

  /**
   * ä»æ–‡ä»¶å¯¼å…¥ç»Ÿè®¡æ•°æ®
   * @param {Context} ctx Koishi ä¸Šä¸‹æ–‡
   * @param {string} filename æ–‡ä»¶åæˆ–æ–‡ä»¶ç»„æ ‡è¯†
   * @param {boolean} [overwrite=false] æ˜¯å¦è¦†ç›–ç°æœ‰æ•°æ®
   * @returns {Promise<string>} å¯¼å…¥ç»“æœæ¶ˆæ¯
   * @throws {Error} å¯¼å…¥å¤±è´¥æ—¶æŠ›å‡ºé”™è¯¯
   */
  async importFromFile(ctx: Context, filename: string, overwrite = false) {
    const dataDir = Utils.getDataDirectory()
    let files = []
    // å¤„ç†ä¸åŒç±»å‹çš„æ–‡ä»¶å
    if (/^\d+-\d+$/.test(filename)) {
      const [groupIdx, fileIdx] = filename.split('-').map(Number)
      const { files: filesList, fileInfo } = await this.listImportFiles(ctx)
      if (groupIdx < 1 || groupIdx > filesList.length || !filesList[groupIdx-1].includes('(N=') ||
          !fileInfo[filesList[groupIdx-1]]?.batchInfo?.files ||
          fileIdx < 1 || fileIdx > fileInfo[filesList[groupIdx-1]]?.batchInfo?.files.length) {
        throw new Error(`æ–‡ä»¶åºå·æ— æ•ˆ`)
      }
      const groupName = filesList[groupIdx-1]
      const targetFile = fileInfo[groupName].batchInfo.files[fileIdx-1]
      const targetPath = path.join(dataDir, targetFile)
      if (fs.existsSync(targetPath)) {
        files.push(targetFile)
      }
    }
    else if (filename.includes('(N=')) {
      const match = filename.match(/(.*)\(N=(\d+)\)$/)
      // æ”¶é›†æ‰¹æ¬¡æ–‡ä»¶
      const [, baseFilename, totalBatches] = match
      for (let i = 1; i <= parseInt(totalBatches); i++) {
        const batchFile = `${baseFilename}-${totalBatches}-${i}.json`
        const batchPath = path.join(dataDir, batchFile)
        if (fs.existsSync(batchPath)) {
          files.push(batchFile)
        }
      }
    }
    else {
      // å•ä¸ªæ–‡ä»¶
      const fileToCheck = filename.endsWith('.json') ? filename : `${filename}.json`
      const filePath = path.join(dataDir, fileToCheck)
      if (fs.existsSync(filePath)) {
        files.push(fileToCheck)
      }
    }
    // æ¸…é™¤ç°æœ‰æ•°æ®
    if (overwrite) {
      await ctx.database.remove('analytics.stat', {})
    }
    // å¯¼å…¥å¤„ç†
    let totalStats = { imported: 0, errors: 0, invalidRecords: 0 }
    for (let i = 0; i < files.length; i++) {
      const content = await fs.promises.readFile(path.join(dataDir, files[i]), 'utf-8')
      const { validRecords, invalidRecords } = this.parseJSON(content)
      const result = await this.importRecords(ctx, validRecords)
      totalStats.imported += result.imported
      totalStats.errors += result.errors
      totalStats.invalidRecords += invalidRecords
    }
    const totalAttempted = totalStats.imported + totalStats.errors
    return files.length === 1
      ? `å¯¼å…¥æˆåŠŸï¼ˆ${totalStats.imported}/${totalAttempted}æ¡ï¼‰`
      : `æ‰¹é‡å¯¼å…¥æˆåŠŸï¼ˆ${totalStats.imported}/${totalAttempted}æ¡ï¼‰`
  },

  /**
   * ä» analytics æ’ä»¶å¯¼å…¥å†å²æ•°æ®
   * @param {Context} ctx Koishi ä¸Šä¸‹æ–‡
   * @param {boolean} [overwrite=false] æ˜¯å¦è¦†ç›–ç°æœ‰æ•°æ®
   * @returns {Promise<string>} å¯¼å…¥ç»“æœæ¶ˆæ¯
   * @throws {Error} å¯¼å…¥å¤±è´¥æ—¶æŠ›å‡ºé”™è¯¯
   */
  async importLegacyData(ctx: Context, overwrite = false) {
    if (!ctx.database.tables['analytics.command']) {throw new Error('æ— å†å²æ•°æ®è¡¨')}
    const [records, bindings] = await Promise.all([
      ctx.database.get('analytics.command', {}),
      ctx.database.get('binding', {})
    ])
    if (!records.length) throw new Error('å†å²æ•°æ®ä¸ºç©º')
    if (overwrite) {
      await ctx.database.remove('analytics.stat', {})
    }
    // ç”¨æˆ·IDæ˜ å°„
    const userIdMap = new Map(
      bindings.filter(b => b.aid)
        .map(b => [b.aid.toString(), { pid: b.pid, platform: b.platform }])
    )
    // åˆå¹¶è®°å½•
    const mergedRecords = new Map()
    records.forEach(cmd => {
      const binding = userIdMap.get(cmd.userId?.toString())
      if (!binding || !cmd.channelId) return
      const commandValue = cmd.name || '_message'
      const key = `${binding.platform}:${cmd.channelId}:${binding.pid}:${commandValue}`
      const timestamp = new Date((cmd.date * 86400000) + ((cmd.hour || 0) * 3600000))
      if (isNaN(timestamp.getTime())) return
      const curr = mergedRecords.get(key) || {
        platform: binding.platform,
        guildId: cmd.channelId,
        userId: binding.pid,
        command: commandValue,
        count: 0,
        lastTime: timestamp,
        userName: '',
        guildName: ''
      }
      curr.count += (cmd.count || 1)
      curr.lastTime = new Date(Math.max(curr.lastTime.getTime(), timestamp.getTime()))
      mergedRecords.set(key, curr)
    })
    const result = await this.importRecords(ctx, Array.from(mergedRecords.values()))
    const totalAttempted = result.imported + result.errors
    return `å¯¼å…¥æˆåŠŸï¼ˆ${result.imported}/${totalAttempted}æ¡ï¼‰`
  },

  /**
   * è§£æJSONæ ¼å¼çš„ç»Ÿè®¡æ•°æ®
   * @param {string} content JSONæ ¼å¼çš„å­—ç¬¦ä¸²å†…å®¹
   * @returns {{validRecords: Array<StatRecord>, totalRecords: number, invalidRecords: number}} è§£æç»“æœï¼ŒåŒ…æ‹¬æœ‰æ•ˆè®°å½•ã€æ€»è®°å½•æ•°å’Œæ— æ•ˆè®°å½•æ•°
   * @throws {Error} è§£æå¤±è´¥æ—¶æŠ›å‡ºé”™è¯¯
   */
  parseJSON(content: string) {
    try {
      const data = JSON.parse(content)
      let invalidRecords = 0
      const validRecords = []
      for (const record of data) {
        if (!record.platform || !record.guildId || !record.userId || !record.command) {
          invalidRecords++
          continue
        }
        const { id, ...rest } = record
        validRecords.push(Utils.normalizeRecord({
          ...rest,
          platform: rest.platform,
          guildId: rest.guildId,
          userId: rest.userId,
          userName: rest.userName ?? '',
          guildName: rest.guildName ?? '',
          command: rest.command,
          count: parseInt(String(rest.count)) || 1,
          lastTime: rest.lastTime ? new Date(rest.lastTime) : new Date()
        }, { sanitizeNames: true }))
      }
      return { validRecords, totalRecords: data.length, invalidRecords }
    } catch (error) {
      throw new Error(error.message)
    }
  },

  /**
   * å°†ç»Ÿè®¡è®°å½•å¯¼å…¥åˆ°æ•°æ®åº“
   * @param {Context} ctx Koishi ä¸Šä¸‹æ–‡
   * @param {Array<StatRecord>} records è¦å¯¼å…¥çš„ç»Ÿè®¡è®°å½•æ•°ç»„
   * @returns {Promise<{imported: number, errors: number}>} å¯¼å…¥ç»“æœï¼ŒåŒ…æ‹¬æˆåŠŸå¯¼å…¥æ•°å’Œé”™è¯¯æ•°
   */
  async importRecords(ctx: Context, records: StatRecord[]) {
    let imported = 0, errors = 0
    const batchSize = 100
    // åˆ†æ‰¹å¤„ç†
    for (let i = 0; i < records.length; i += batchSize) {
      const batch = records.slice(i, i + batchSize)
      await Promise.all(batch.map(async record => {
        const query = {
          platform: record.platform,
          guildId: record.guildId,
          userId: record.userId,
          command: record.command
        }
        try {
          const [existing] = await ctx.database.get('analytics.stat', query)
          if (existing) {
            // æ›´æ–°ç°æœ‰è®°å½•
            const existingUserName = existing.userName?.trim() || '';
            const recordUserName = Utils.sanitizeString(record.userName || '');
            const newUserName = existingUserName && recordUserName
              ? (record.lastTime > existing.lastTime ? recordUserName : existingUserName)
              : (existingUserName || recordUserName);
            const existingGuildName = existing.guildName?.trim() || '';
            const recordGuildName = Utils.sanitizeString(record.guildName || '');
            const newGuildName = existingGuildName && recordGuildName
              ? (record.lastTime > existing.lastTime ? recordGuildName : existingGuildName)
              : (existingGuildName || recordGuildName);
            await ctx.database.set('analytics.stat', query, {
              count: existing.count + (record.count || 1),
              lastTime: record.lastTime > existing.lastTime ? record.lastTime : existing.lastTime,
              userName: newUserName,
              guildName: newGuildName
            })
          } else {
            // åˆ›å»ºæ–°è®°å½•
            await ctx.database.create('analytics.stat', {
              ...query,
              count: record.count || 1,
              lastTime: record.lastTime || new Date(),
              userName: Utils.sanitizeString(record.userName || ''),
              guildName: Utils.sanitizeString(record.guildName || '')
            })
          }
          imported++
        } catch (e) {
          errors++
        }
      }))
    }
    return { imported, errors }
  },

  /**
   * æ³¨å†Œå¯¼å…¥å¯¼å‡ºå‘½ä»¤
   * @param {Context} ctx Koishi ä¸Šä¸‹æ–‡
   * @param {any} parent çˆ¶å‘½ä»¤å¯¹è±¡
   */
  registerCommands(ctx: Context, parent: any) {
    parent.subcommand('.export', 'å¯¼å‡ºç»Ÿè®¡æ•°æ®', { authority: 4 })
      .option('user', '-u [user:string] æŒ‡å®šç”¨æˆ·')
      .option('platform', '-p [platform:string] æŒ‡å®šå¹³å°')
      .option('guild', '-g [guild:string] æŒ‡å®šç¾¤ç»„')
      .option('command', '-c [command:string] æŒ‡å®šå‘½ä»¤')
      .action(async ({ options, session }) => {
        try {
          // å‘é€è¿›åº¦æç¤º
          if (Object.values(options).some(Boolean)) {
            await session.send('æ­£åœ¨å¯¼å‡º...')
          }
          // æ‰§è¡Œå¯¼å‡º
          const result = await this.exportToFile(ctx, 'stat', {
            userId: options.user,
            platform: options.platform,
            guildId: options.guild,
            command: options.command
          })
          // è¿”å›å¯¼å‡ºç»“æœæ¶ˆæ¯
          if (result.batches === 1) {
            return `å¯¼å‡ºæˆåŠŸï¼ˆ${result.count}æ¡ï¼‰ï¼š\n- ${result.files[0].filename}`
          } else {
            const fileList = result.files.map(f => `- ${f.filename}`).join('\n')
            return `å¯¼å‡ºæˆåŠŸï¼ˆ${result.count}æ¡ï¼‰ï¼š\n${fileList}`
          }
        } catch (e) {
          return `å¯¼å‡ºå¤±è´¥ï¼š${e.message}`
        }
      })
    parent.subcommand('.import [selector:number]', 'å¯¼å…¥ç»Ÿè®¡æ•°æ®', { authority: 4 })
      .option('force', '-f è¦†ç›–ç°æœ‰æ•°æ®')
      .option('database', '-d ä»å†å²æ•°æ®åº“å¯¼å…¥')
      .action(async ({ session, options, args }) => {
        try {
          // ä»å†å²æ•°æ®åº“å¯¼å…¥
          if (options.database) {
            session.send('æ­£åœ¨å¯¼å…¥å†å²è®°å½•...')
            try {
              return await this.importLegacyData(ctx, options.force)
            } catch (e) {
              return e.message
            }
          }
          // è·å–å¯å¯¼å…¥æ–‡ä»¶åˆ—è¡¨
          const { files, fileInfo } = await this.listImportFiles(ctx)
          if (!files.length) {
            return 'æœªæ‰¾åˆ°å†å²è®°å½•æ–‡ä»¶'
          }
          // ä½¿ç”¨åºå·é€‰æ‹©æ–‡ä»¶å¯¼å…¥
          const selector = args[0]
          if (selector) {
            if (selector > 0 && selector <= files.length) {
              const targetFile = files[selector - 1]
              await session.send(`æ­£åœ¨${options.force ? 'è¦†ç›–' : ''}å¯¼å…¥æ–‡ä»¶ï¼š\n- ${targetFile}`)
              return await this.importFromFile(ctx, targetFile, options.force)
            }
            return 'è¯·è¾“å…¥æ­£ç¡®çš„åºå·'
          }
          // æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
          const fileList = files.map((file, index) => {
            const info = fileInfo[file] || {}
            let prefix = 'ğŸ“„'
            if (file.includes('(N=')) {
              prefix = 'ğŸ“¦'
            } else if (info.isBatch) {
              prefix = 'ğŸ“'
            }
            return `${index + 1}.${prefix}${file}`
          }).join('\n')
          return `ä½¿ç”¨ import [åºå·]å¯¼å…¥å¯¹åº”æ–‡ä»¶ï¼š\n${fileList}`
        } catch (e) {
          return `å¯¼å…¥å¤±è´¥ï¼š${e.message}`
        }
      })
  }
}